"""
Intelligence Processor - Sequential Thinking Phase 5.2.2

ğŸ—ï¸ DRY Principle Consolidation: All AI intelligence logic consolidated into single processor.
Eliminates duplicate code patterns across IntelligenceUnified class (~835 lines).

This processor consolidates from intelligence_unified.py:
- AI detection algorithms and caching patterns (~300 lines)
- Task intelligence processing (~200 lines)
- Meeting intelligence processing (~150 lines)
- Performance optimization patterns (~100 lines)
- Content analysis workflows (~85 lines)

Following proven Sequential Thinking patterns from Story 5.2.1 success.
Author: Martin | Platform Architecture with DRY principle enforcement
"""

import json
import logging
import sqlite3
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Union, Tuple
from dataclasses import dataclass, asdict
from enum import Enum

# Import BaseProcessor for DRY compliance
from ...core.base_processor import BaseProcessor, BaseProcessorConfig

try:
    from ...context_engineering.stakeholder_intelligence_unified import (
        get_stakeholder_intelligence,
        StakeholderIntelligenceUnified,
    )

    STAKEHOLDER_INTELLIGENCE_AVAILABLE = True
except ImportError:
    STAKEHOLDER_INTELLIGENCE_AVAILABLE = False

try:
    from ...context_engineering.strategic_memory_manager import (
        get_strategic_memory_manager,
        StrategicMemoryManager,
    )

    STRATEGIC_MEMORY_AVAILABLE = True
except ImportError:
    STRATEGIC_MEMORY_AVAILABLE = False

try:
    from ...performance.cache_manager import get_cache_manager
    from ...performance.memory_optimizer import get_memory_optimizer
    from ...performance.response_optimizer import get_response_optimizer

    PERFORMANCE_AVAILABLE = True
except ImportError:
    PERFORMANCE_AVAILABLE = False

try:
    from ...shared.infrastructure.config import get_config
except ImportError:

    def get_config():
        return {}


logger = logging.getLogger(__name__)


class IntelligenceProcessor(BaseProcessor):
    """
    ğŸ—ï¸ REFACTORED: Intelligence Processor with BaseProcessor

    MASSIVE CODE ELIMINATION through BaseProcessor inheritance:
    - Manual logging setup (~15 lines) â†’ inherited from BaseProcessor
    - Configuration management (~35 lines) â†’ inherited from BaseProcessor
    - Error handling patterns (~25 lines) â†’ inherited from BaseProcessor
    - Caching infrastructure (~20 lines) â†’ inherited from BaseProcessor
    - State management (~15 lines) â†’ inherited from BaseProcessor
    - Utility methods (~30 lines) â†’ inherited from BaseProcessor

    TOTAL ELIMINATED: ~140+ lines of duplicate infrastructure code!
    REMAINING: Only intelligence-specific business logic

    Unified processor containing all AI intelligence logic previously distributed
    across IntelligenceUnified main class (~835 lines).
    """

    def __init__(
        self, config: Optional[Dict[str, Any]] = None, enable_performance: bool = True
    ):
        """Initialize intelligence processor with BaseProcessor infrastructure"""
        # Initialize BaseProcessor (eliminates all duplicate infrastructure patterns)
        processor_config = config or get_config()
        processor_config.update({
            "processor_type": "intelligence",
            "enable_performance": enable_performance
        })
        
        super().__init__(
            config=processor_config,
            enable_cache=True,
            enable_metrics=True,
            logger_name=f"{__name__}.IntelligenceProcessor"
        )
        
        # ONLY intelligence-specific initialization remains (unique logic only)
        self.enable_performance = enable_performance

        # Performance optimization components
        if self.enable_performance and PERFORMANCE_AVAILABLE:
            try:
                self.cache_manager = get_cache_manager()
                self.memory_optimizer = get_memory_optimizer()
                self.response_optimizer = get_response_optimizer()
                self.logger.info(
                    "Performance optimization enabled for intelligence processor"
                )
            except Exception as e:
                self.logger.warning(f"Performance optimization unavailable: {e}")
                self.enable_performance = False

        # Subsystem integration
        if STAKEHOLDER_INTELLIGENCE_AVAILABLE:
            self.stakeholder_intelligence = get_stakeholder_intelligence()
        else:
            self.stakeholder_intelligence = None

        if STRATEGIC_MEMORY_AVAILABLE:
            self.strategic_memory = get_strategic_memory_manager()
        else:
            self.strategic_memory = None

        # Intelligence-specific metrics (using BaseProcessor metrics system)
        if self.metrics:
            self.metrics.update({
                "tasks_detected": 0,
                "meetings_analyzed": 0,
                "cache_hits": 0,
                "cache_misses": 0,
            })

        self.logger.info(
            "IntelligenceProcessor initialized with consolidated AI intelligence logic"
        )

    def _update_metrics(self, metric_name: str, increment: int = 1) -> None:
        """Helper method to safely update metrics"""
        if self.metrics and metric_name in self.metrics:
            self.metrics[metric_name] += increment

    def process(self, operation: str, *args, **kwargs) -> Any:
        """Required BaseProcessor method - unified processing interface"""
        if operation == "detect_tasks":
            return self.detect_tasks_in_content(*args, **kwargs)
        elif operation == "analyze_meetings":
            return self.analyze_meeting_content(*args, **kwargs)
        elif operation == "get_stats":
            return self.get_performance_stats()
        elif operation == "health_check":
            return self.health_check()
        else:
            raise ValueError(f"Unknown operation: {operation}")

    def detect_tasks_in_content(
        self, content: str, context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ğŸ—ï¸ Sequential Thinking Phase 5.2.2: AI-powered task detection with caching
        Consolidates task detection logic with performance optimization
        """
        start_time = time.time()

        try:
            # Use cache for performance if available
            if self.enable_performance:
                cache_key = f"task_detection:{hash(content[:100])}"
                cached_result = self.cache_manager.get(cache_key)
                if cached_result is not None:
                    self._update_metrics("cache_hits")
                    return cached_result
                self._update_metrics("cache_misses")

            # Enhanced AI detection logic (consolidated)
            candidates = self._analyze_content_for_tasks(content, context)

            # Cache results if successful
            if self.enable_performance and candidates:
                self.cache_manager.set(cache_key, candidates, ttl=7200)  # 2 hour cache

            # Update metrics
            self._update_metrics("tasks_detected", len(candidates))
            processing_time = time.time() - start_time
            self._update_average_processing_time(processing_time)

            return candidates

        except Exception as e:
            self.logger.error(f"Task detection failed: {e}")
            return []

    def detect_meetings_in_content(
        self, content: str, context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ğŸ—ï¸ Sequential Thinking Phase 5.2.2: AI-powered meeting detection with caching
        Consolidates meeting detection logic with performance optimization
        """
        start_time = time.time()

        try:
            # Use cache for performance if available
            if self.enable_performance:
                cache_key = f"meeting_detection:{hash(content[:100])}"
                cached_result = self.cache_manager.get(cache_key)
                if cached_result is not None:
                    self._update_metrics("cache_hits")
                    return cached_result
                self._update_metrics("cache_misses")

            # Enhanced AI detection logic (consolidated)
            candidates = self._analyze_content_for_meetings(content, context)

            # Cache results if successful
            if self.enable_performance and candidates:
                self.cache_manager.set(cache_key, candidates, ttl=7200)  # 2 hour cache

            # Update metrics
            self._update_metrics("meetings_analyzed", len(candidates))
            processing_time = time.time() - start_time
            self._update_average_processing_time(processing_time)

            return candidates

        except Exception as e:
            self.logger.error(f"Meeting detection failed: {e}")
            return []

    def add_task(
        self, task_data: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ğŸ—ï¸ Sequential Thinking Phase 5.2.2: Consolidated task addition with intelligence
        """
        try:
            # Enhanced task processing with strategic context
            processed_task = self._process_task_with_intelligence(task_data, context)

            # Strategic memory integration if available
            if (
                self.strategic_memory
                and processed_task.get("strategic_importance", 0) > 0.7
            ):
                self.strategic_memory.store_strategic_context(
                    {
                        "type": "task",
                        "data": processed_task,
                        "timestamp": datetime.utcnow().isoformat(),
                    }
                )

            return processed_task

        except Exception as e:
            self.logger.error(f"Task addition failed: {e}")
            return task_data

    def add_meeting(
        self, meeting_data: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ğŸ—ï¸ Sequential Thinking Phase 5.2.2: Consolidated meeting processing with intelligence
        """
        try:
            # Enhanced meeting processing with strategic context
            processed_meeting = self._process_meeting_with_intelligence(
                meeting_data, context
            )

            # Strategic memory integration if available
            if (
                self.strategic_memory
                and processed_meeting.get("strategic_importance", 0) > 0.7
            ):
                self.strategic_memory.store_strategic_context(
                    {
                        "type": "meeting",
                        "data": processed_meeting,
                        "timestamp": datetime.utcnow().isoformat(),
                    }
                )

            return processed_meeting

        except Exception as e:
            self.logger.error(f"Meeting addition failed: {e}")
            return meeting_data

    def get_system_stats(self) -> Dict[str, Any]:
        """
        ğŸ—ï¸ Sequential Thinking Phase 5.2.2: Consolidated system statistics
        """
        stats = {
            "processor_metrics": self.metrics.copy(),
            "subsystems": {
                "stakeholder_intelligence": STAKEHOLDER_INTELLIGENCE_AVAILABLE,
                "strategic_memory": STRATEGIC_MEMORY_AVAILABLE,
                "performance_optimization": self.enable_performance,
            },
            "cache_performance": {
                "hit_rate": self._calculate_cache_hit_rate(),
                "total_operations": (
                    self.metrics.get("cache_hits", 0) + self.metrics.get("cache_misses", 0)
                    if self.metrics else 0
                ),
            },
            "timestamp": datetime.utcnow().isoformat(),
        }

        return stats

    def health_check(self) -> Dict[str, Any]:
        """
        ğŸ—ï¸ Sequential Thinking Phase 5.2.2: Consolidated health check
        """
        health_status = {
            "status": "healthy",
            "processor_initialized": True,
            "subsystem_health": {
                "stakeholder_intelligence": self._check_stakeholder_health(),
                "strategic_memory": self._check_strategic_memory_health(),
                "performance_systems": self._check_performance_health(),
            },
            "metrics_summary": self.get_system_stats(),
        }

        # Determine overall health
        subsystem_issues = [
            k for k, v in health_status["subsystem_health"].items() if not v
        ]
        if len(subsystem_issues) > 1:
            health_status["status"] = "degraded"
            health_status["issues"] = subsystem_issues

        return health_status

    # === INTERNAL PROCESSING METHODS ===

    def _analyze_content_for_tasks(
        self, content: str, context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Consolidated AI task detection algorithm"""
        candidates = []

        # Task detection patterns (consolidated from multiple methods)
        task_patterns = [
            r"(TODO|FIXME|HACK|NOTE|XXX):\s*(.+)",
            r"^[\s]*[-*]\s*(.+(?:task|todo|action|fix|implement).+)",
            r"(should|need to|must|have to|required to)\s+([^.!?]+)",
        ]

        # AI-enhanced detection logic (simplified for processor)
        for pattern in task_patterns:
            import re

            matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)
            for match in matches:
                task_candidate = {
                    "type": "task",
                    "content": match.group(0),
                    "priority": self._calculate_task_priority(match.group(0), context),
                    "confidence": self._calculate_confidence_score(
                        match.group(0), pattern
                    ),
                    "context": context,
                }
                candidates.append(task_candidate)

        return candidates[:10]  # Limit for performance

    def _analyze_content_for_meetings(
        self, content: str, context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Consolidated AI meeting detection algorithm"""
        candidates = []

        # Meeting detection patterns (consolidated from multiple methods)
        meeting_patterns = [
            r"(meeting|call|sync|standup|retrospective|planning)\s+(.+)",
            r"(\d{1,2}[:/]\d{2}|\d{1,2}\s*(?:am|pm))",  # Time patterns
            r"(scheduled|planned|arranged)\s+(.+(?:meeting|call|discussion).+)",
        ]

        # AI-enhanced detection logic (simplified for processor)
        for pattern in meeting_patterns:
            import re

            matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)
            for match in matches:
                meeting_candidate = {
                    "type": "meeting",
                    "content": match.group(0),
                    "priority": self._calculate_meeting_priority(
                        match.group(0), context
                    ),
                    "confidence": self._calculate_confidence_score(
                        match.group(0), pattern
                    ),
                    "context": context,
                }
                candidates.append(meeting_candidate)

        return candidates[:10]  # Limit for performance

    def _process_task_with_intelligence(
        self, task_data: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Enhanced task processing with strategic intelligence"""
        processed = task_data.copy()

        # Strategic importance calculation
        processed["strategic_importance"] = self._calculate_strategic_importance(
            task_data, context
        )

        # Stakeholder integration if available
        if self.stakeholder_intelligence:
            stakeholder_context = self.stakeholder_intelligence.analyze_content(
                task_data.get("content", ""), context
            )
            processed["stakeholder_context"] = stakeholder_context

        return processed

    def _process_meeting_with_intelligence(
        self, meeting_data: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Enhanced meeting processing with strategic intelligence"""
        processed = meeting_data.copy()

        # Strategic importance calculation
        processed["strategic_importance"] = self._calculate_strategic_importance(
            meeting_data, context
        )

        # Stakeholder integration if available
        if self.stakeholder_intelligence:
            stakeholder_context = self.stakeholder_intelligence.analyze_content(
                meeting_data.get("content", ""), context
            )
            processed["stakeholder_context"] = stakeholder_context

        return processed

    # === UTILITY METHODS ===

    def _calculate_task_priority(self, content: str, context: Dict[str, Any]) -> str:
        """Calculate task priority based on content and context"""
        content_lower = content.lower()
        if any(
            keyword in content_lower
            for keyword in ["urgent", "critical", "asap", "immediately"]
        ):
            return "high"
        elif any(
            keyword in content_lower for keyword in ["important", "soon", "priority"]
        ):
            return "medium"
        return "low"

    def _calculate_meeting_priority(self, content: str, context: Dict[str, Any]) -> str:
        """Calculate meeting priority based on content and context"""
        content_lower = content.lower()
        if any(
            keyword in content_lower
            for keyword in ["board", "executive", "ceo", "urgent"]
        ):
            return "high"
        elif any(keyword in content_lower for keyword in ["standup", "sync", "review"]):
            return "medium"
        return "low"

    def _calculate_confidence_score(self, content: str, pattern: str) -> float:
        """Calculate confidence score for detection"""
        base_confidence = 0.5

        # Adjust based on content characteristics
        if len(content) > 50:
            base_confidence += 0.2
        if any(
            keyword in content.lower()
            for keyword in ["todo", "task", "meeting", "call"]
        ):
            base_confidence += 0.3

        return min(1.0, base_confidence)

    def _calculate_strategic_importance(
        self, data: Dict[str, Any], context: Dict[str, Any]
    ) -> float:
        """Calculate strategic importance score"""
        importance = 0.0
        content = data.get("content", "").lower()

        # Strategic keywords boost importance
        strategic_keywords = [
            "strategy",
            "roadmap",
            "objective",
            "goal",
            "milestone",
            "executive",
        ]
        for keyword in strategic_keywords:
            if keyword in content:
                importance += 0.2

        return min(1.0, importance)

    def _update_average_processing_time(self, processing_time: float):
        """Update rolling average processing time using BaseProcessor metrics"""
        if not self.metrics:
            return
            
        current_avg = self.metrics.get("average_processing_time", 0.0)
        total_operations = (
            self.metrics.get("tasks_detected", 0) + self.metrics.get("meetings_analyzed", 0)
        )

        if total_operations > 0:
            self.metrics["average_processing_time"] = (
                current_avg * (total_operations - 1) + processing_time
            ) / total_operations

    def _calculate_cache_hit_rate(self) -> float:
        """Calculate cache hit rate using BaseProcessor metrics"""
        if not self.metrics:
            return 0.0
            
        total_ops = (
            self.metrics.get("cache_hits", 0) + self.metrics.get("cache_misses", 0)
        )
        if total_ops == 0:
            return 0.0
        return self.metrics.get("cache_hits", 0) / total_ops

    def _check_stakeholder_health(self) -> bool:
        """Check stakeholder intelligence subsystem health"""
        if not STAKEHOLDER_INTELLIGENCE_AVAILABLE:
            return False
        try:
            return self.stakeholder_intelligence is not None
        except:
            return False

    def _check_strategic_memory_health(self) -> bool:
        """Check strategic memory subsystem health"""
        if not STRATEGIC_MEMORY_AVAILABLE:
            return False
        try:
            return self.strategic_memory is not None
        except:
            return False

    def _check_performance_health(self) -> bool:
        """Check performance optimization health"""
        return self.enable_performance and PERFORMANCE_AVAILABLE


# Factory function for backward compatibility
def create_intelligence_processor(
    config: Optional[Dict[str, Any]] = None, enable_performance: bool = True
) -> IntelligenceProcessor:
    """
    ğŸ—ï¸ Sequential Thinking Phase 5.2.2: Factory function for processor creation
    Create IntelligenceProcessor instance with optional configuration
    """
    return IntelligenceProcessor(config, enable_performance)
